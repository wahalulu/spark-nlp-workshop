{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NLU_Stemmer_example.ipynb","provenance":[{"file_id":"1pgqoRJ6yGWbTLWdLnRvwG5DLSU3rxuMq","timestamp":1599401652794},{"file_id":"1JrlfuV2jNGTdOXvaWIoHTSf6BscDMkN7","timestamp":1599401257319},{"file_id":"1svpqtC3cY6JnRGeJngIPl2raqxdowpyi","timestamp":1599400881246},{"file_id":"1tW833T3HS8F5Lvn6LgeDd5LW5226syKN","timestamp":1599398724652},{"file_id":"1CYzHfQyFCdvIOVO2Z5aggVI9c0hDEOrw","timestamp":1599354735581}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"rBXrqlGEYA8G"},"source":["![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n","\n","[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/nlu/blob/master/examples/collab/Text_Pre_Processing_and_Cleaning/NLU_Stemmer_example.ipynb)\n","# Stemming with NLU \n","\n","Stemming returns the base form, the so called stem / root or base word of every token in the input data.    \n","\n","I. e. 'He was hungry' becomes 'He wa hungri'\n","\n","\n","Stemming works by applying a heuristic process that strips and mutates suffixes on  words.\n","\n","\n","# 1. Install Java and NLU"]},{"cell_type":"code","metadata":{"id":"M2-GiYL6xurJ"},"source":["\n","import os\n","! apt-get update -qq > /dev/null   \n","# Install java\n","! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n","! pip install nlu > /dev/null   "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N_CL8HZ8Ydry"},"source":["## 2. Load Model and stemm sample string"]},{"cell_type":"code","metadata":{"id":"j2ZZZvr1uGpx","executionInfo":{"status":"ok","timestamp":1604902897218,"user_tz":-60,"elapsed":89623,"user":{"displayName":"Christian Kasim Loan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqAD-ircKP-s5Eh6JSdkDggDczfqQbJGU_IRb4Hw=s64","userId":"14469489166467359317"}},"outputId":"3432db71-e6fc-4fdc-87da-f2d9a7cddb9d","colab":{"base_uri":"https://localhost:8080/","height":106}},"source":["import nlu\n","pipe = nlu.load('en.stem')\n","pipe.predict('He was suprised by the diversity of NLU')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence</th>\n","      <th>stem</th>\n","    </tr>\n","    <tr>\n","      <th>origin_index</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>He was suprised by the diversity of NLU</td>\n","      <td>[he, wa, supris, by, the, divers, of, nlu]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                             sentence                                        stem\n","origin_index                                                                                     \n","0             He was suprised by the diversity of NLU  [he, wa, supris, by, the, divers, of, nlu]"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"IRSEzc-RCceu"},"source":["# 3. Get one row per stemmed token by setting outputlevel to token.    \n","This lets us compare what the original token was and what it was stemmed to to. "]},{"cell_type":"code","metadata":{"id":"9bujAZtOCfRW","executionInfo":{"status":"ok","timestamp":1604902898186,"user_tz":-60,"elapsed":90573,"user":{"displayName":"Christian Kasim Loan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqAD-ircKP-s5Eh6JSdkDggDczfqQbJGU_IRb4Hw=s64","userId":"14469489166467359317"}},"outputId":"053375aa-fe3a-4a0c-ea25-cb17cdce8313","colab":{"base_uri":"https://localhost:8080/","height":314}},"source":["pipe.predict('He was suprised by the diversity of NLU', output_level='token')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>token</th>\n","      <th>stem</th>\n","    </tr>\n","    <tr>\n","      <th>origin_index</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>He</td>\n","      <td>he</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>was</td>\n","      <td>wa</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>suprised</td>\n","      <td>supris</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>by</td>\n","      <td>by</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>the</td>\n","      <td>the</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>diversity</td>\n","      <td>divers</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>of</td>\n","      <td>of</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>NLU</td>\n","      <td>nlu</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                  token    stem\n","origin_index                   \n","0                    He      he\n","0                   was      wa\n","0              suprised  supris\n","0                    by      by\n","0                   the     the\n","0             diversity  divers\n","0                    of      of\n","0                   NLU     nlu"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"av7EiK4adb24"},"source":["# 4. Checkout the Stemm models NLU has to offer for other languages than English!"]},{"cell_type":"code","metadata":{"id":"hZ8xLHY7dgJ8","executionInfo":{"status":"ok","timestamp":1604902898189,"user_tz":-60,"elapsed":90564,"user":{"displayName":"Christian Kasim Loan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqAD-ircKP-s5Eh6JSdkDggDczfqQbJGU_IRb4Hw=s64","userId":"14469489166467359317"}},"outputId":"4d0860c2-21b9-4bcc-9c52-725e341a1f0e","colab":{"base_uri":"https://localhost:8080/"}},"source":["nlu.print_all_model_kinds_for_action('stem')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["For language <en> NLU provides the following Models : \n","nlu.load('en.stem') returns Spark NLP model stemmer\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"TsRxB950elTp"},"source":["## 4.1 Let's try German stemming!"]},{"cell_type":"code","metadata":{"id":"5d_J7-20dvCw","executionInfo":{"status":"ok","timestamp":1604902903460,"user_tz":-60,"elapsed":95822,"user":{"displayName":"Christian Kasim Loan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqAD-ircKP-s5Eh6JSdkDggDczfqQbJGU_IRb4Hw=s64","userId":"14469489166467359317"}},"outputId":"d61f6dbd-b3e9-4fca-a7bd-0473be6cbd19","colab":{"base_uri":"https://localhost:8080/","height":343}},"source":["nlu.load('de.stem').predict(\"Er war von der Vielfältigkeit des NLU Packets begeistert\",output_level='token')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>token</th>\n","      <th>stem</th>\n","    </tr>\n","    <tr>\n","      <th>origin_index</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Er</td>\n","      <td>er</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>war</td>\n","      <td>war</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>von</td>\n","      <td>von</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>der</td>\n","      <td>der</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Vielfältigkeit</td>\n","      <td>vielfältigkeit</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>des</td>\n","      <td>de</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>NLU</td>\n","      <td>nlu</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Packets</td>\n","      <td>packet</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>begeistert</td>\n","      <td>begeistert</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                       token            stem\n","origin_index                                \n","0                         Er              er\n","0                        war             war\n","0                        von             von\n","0                        der             der\n","0             Vielfältigkeit  vielfältigkeit\n","0                        des              de\n","0                        NLU             nlu\n","0                    Packets          packet\n","0                 begeistert      begeistert"]},"metadata":{"tags":[]},"execution_count":5}]}]}