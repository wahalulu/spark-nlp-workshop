{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NLU_Spellchecking_example.ipynb","provenance":[{"file_id":"1pgqoRJ6yGWbTLWdLnRvwG5DLSU3rxuMq","timestamp":1599401652794},{"file_id":"1JrlfuV2jNGTdOXvaWIoHTSf6BscDMkN7","timestamp":1599401257319},{"file_id":"1svpqtC3cY6JnRGeJngIPl2raqxdowpyi","timestamp":1599400881246},{"file_id":"1tW833T3HS8F5Lvn6LgeDd5LW5226syKN","timestamp":1599398724652},{"file_id":"1CYzHfQyFCdvIOVO2Z5aggVI9c0hDEOrw","timestamp":1599354735581}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"rBXrqlGEYA8G"},"source":["![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n","\n","[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/nlu/blob/master/examples/collab/Text_Pre_Processing_and_Cleaning/NLU_Stemmer_example.ipynb)\n","# Stemming with NLU \n","\n","Stemming returns the base form, the so called stem / root or base word of every token in the input data.    \n","\n","I. e. 'He was hungry' becomes 'He wa hungri'\n","\n","\n","Stemming works by applying a heuristic process that strips and mutates suffixes on  words.\n","\n","\n","# 1. Install Java and NLU"]},{"cell_type":"code","metadata":{"id":"M2-GiYL6xurJ"},"source":["\n","import os\n","! apt-get update -qq > /dev/null   \n","# Install java\n","! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n","! pip install nlu > /dev/null   "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N_CL8HZ8Ydry"},"source":["## 2. Load Model and stemm sample string"]},{"cell_type":"code","metadata":{"id":"j2ZZZvr1uGpx","executionInfo":{"status":"ok","timestamp":1604902908314,"user_tz":-60,"elapsed":91266,"user":{"displayName":"Christian Kasim Loan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqAD-ircKP-s5Eh6JSdkDggDczfqQbJGU_IRb4Hw=s64","userId":"14469489166467359317"}},"outputId":"5f04eb7b-5807-4350-e8e1-82fd52bf6abc","colab":{"base_uri":"https://localhost:8080/","height":106}},"source":["import nlu\n","pipe = nlu.load('en.stem')\n","pipe.predict('He was suprised by the diversity of NLU')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>stem</th>\n","      <th>sentence</th>\n","    </tr>\n","    <tr>\n","      <th>origin_index</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[he, wa, supris, by, the, divers, of, nlu]</td>\n","      <td>He was suprised by the diversity of NLU</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                    stem                                 sentence\n","origin_index                                                                                     \n","0             [he, wa, supris, by, the, divers, of, nlu]  He was suprised by the diversity of NLU"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"IRSEzc-RCceu"},"source":["# 3. Get one row per stemmed token by setting outputlevel to token.    \n","This lets us compare what the original token was and what it was stemmed to to. "]},{"cell_type":"code","metadata":{"id":"9bujAZtOCfRW","executionInfo":{"status":"ok","timestamp":1604902909510,"user_tz":-60,"elapsed":92452,"user":{"displayName":"Christian Kasim Loan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqAD-ircKP-s5Eh6JSdkDggDczfqQbJGU_IRb4Hw=s64","userId":"14469489166467359317"}},"outputId":"d3133e50-fa88-4e66-a06d-e89fc1f6e777","colab":{"base_uri":"https://localhost:8080/","height":314}},"source":["pipe.predict('He was suprised by the diversity of NLU', output_level='token')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>stem</th>\n","      <th>token</th>\n","    </tr>\n","    <tr>\n","      <th>origin_index</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>he</td>\n","      <td>He</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>wa</td>\n","      <td>was</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>supris</td>\n","      <td>suprised</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>by</td>\n","      <td>by</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>the</td>\n","      <td>the</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>divers</td>\n","      <td>diversity</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>of</td>\n","      <td>of</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>nlu</td>\n","      <td>NLU</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                stem      token\n","origin_index                   \n","0                 he         He\n","0                 wa        was\n","0             supris   suprised\n","0                 by         by\n","0                the        the\n","0             divers  diversity\n","0                 of         of\n","0                nlu        NLU"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"av7EiK4adb24"},"source":["# 4. Checkout the Stemm models NLU has to offer for other languages than English!"]},{"cell_type":"code","metadata":{"id":"hZ8xLHY7dgJ8","executionInfo":{"status":"ok","timestamp":1604902909519,"user_tz":-60,"elapsed":92454,"user":{"displayName":"Christian Kasim Loan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqAD-ircKP-s5Eh6JSdkDggDczfqQbJGU_IRb4Hw=s64","userId":"14469489166467359317"}},"outputId":"11fdae65-738d-43aa-b65a-8d3698498b01","colab":{"base_uri":"https://localhost:8080/"}},"source":["nlu.print_all_model_kinds_for_action('stem')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["For language <en> NLU provides the following Models : \n","nlu.load('en.stem') returns Spark NLP model stemmer\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"TsRxB950elTp"},"source":["## 4.1 Let's try German stemming!"]},{"cell_type":"code","metadata":{"id":"5d_J7-20dvCw","executionInfo":{"status":"ok","timestamp":1604902910863,"user_tz":-60,"elapsed":93792,"user":{"displayName":"Christian Kasim Loan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqAD-ircKP-s5Eh6JSdkDggDczfqQbJGU_IRb4Hw=s64","userId":"14469489166467359317"}},"outputId":"a0e09d46-4dd2-430e-f91d-513ad7fffe2d","colab":{"base_uri":"https://localhost:8080/","height":343}},"source":["nlu.load('de.stem').predict(\"Er war von der Vielfältigkeit des NLU Packets begeistert\",output_level='token')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>stem</th>\n","      <th>token</th>\n","    </tr>\n","    <tr>\n","      <th>origin_index</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>er</td>\n","      <td>Er</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>war</td>\n","      <td>war</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>von</td>\n","      <td>von</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>der</td>\n","      <td>der</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>vielfältigkeit</td>\n","      <td>Vielfältigkeit</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>de</td>\n","      <td>des</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>nlu</td>\n","      <td>NLU</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>packet</td>\n","      <td>Packets</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>begeistert</td>\n","      <td>begeistert</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                        stem           token\n","origin_index                                \n","0                         er              Er\n","0                        war             war\n","0                        von             von\n","0                        der             der\n","0             vielfältigkeit  Vielfältigkeit\n","0                         de             des\n","0                        nlu             NLU\n","0                     packet         Packets\n","0                 begeistert      begeistert"]},"metadata":{"tags":[]},"execution_count":5}]}]}