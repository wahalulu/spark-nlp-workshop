{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NLU_Lemmatization.ipynb","provenance":[{"file_id":"1pgqoRJ6yGWbTLWdLnRvwG5DLSU3rxuMq","timestamp":1599401652794},{"file_id":"1JrlfuV2jNGTdOXvaWIoHTSf6BscDMkN7","timestamp":1599401257319},{"file_id":"1svpqtC3cY6JnRGeJngIPl2raqxdowpyi","timestamp":1599400881246},{"file_id":"1tW833T3HS8F5Lvn6LgeDd5LW5226syKN","timestamp":1599398724652},{"file_id":"1CYzHfQyFCdvIOVO2Z5aggVI9c0hDEOrw","timestamp":1599354735581}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"rBXrqlGEYA8G"},"source":["![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n","\n","[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/nlu/blob/master/examples/collab/Text_Pre_Processing_and_Cleaning/NLU_Lemmatization.ipynb)\n","\n","# Lemmatization with NLU \n","\n","Lemmatizing returns the base form, the so called lemma of every token in the input data.    \n","\n","I. e. 'He was hungry' becomes 'He be hungry'\n","\n","The Lemmatizer works by operating on a dictionary and taking context into account. This lets the Lemmatizer dervie a different base word for for a word in two different contexts which depends on the Part of Speech tags. \n","\n","\n","\n","This is the main difference  to Stemming, which solves the same problem by applying a heuristic process that removes the end of words.\n","\n","\n","# 1. Install Java and NLU"]},{"cell_type":"code","metadata":{"id":"M2-GiYL6xurJ"},"source":["\n","import os\n","! apt-get update -qq > /dev/null   \n","# Install java\n","! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n","! pip install nlu > /dev/null    "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N_CL8HZ8Ydry"},"source":["## 2. Load Model and lemmatize sample string"]},{"cell_type":"code","metadata":{"id":"j2ZZZvr1uGpx","executionInfo":{"status":"ok","timestamp":1604903314116,"user_tz":-60,"elapsed":12361,"user":{"displayName":"Christian Kasim Loan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqAD-ircKP-s5Eh6JSdkDggDczfqQbJGU_IRb4Hw=s64","userId":"14469489166467359317"}},"outputId":"2e90b0eb-30c9-423c-bdf5-7ed0ed431063","colab":{"base_uri":"https://localhost:8080/","height":157}},"source":["import nlu\n","pipe = nlu.load('en.lemma')\n","pipe.predict('He was suprised by the diversity of NLU')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["lemma_antbnc download started this may take some time.\n","Approximate size to download 907.6 KB\n","[OK!]\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>en_lemma</th>\n","      <th>document</th>\n","    </tr>\n","    <tr>\n","      <th>origin_index</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[He, be, suprise, by, the, diversity, of, NLU]</td>\n","      <td>He was suprised by the diversity of NLU</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                    en_lemma                                 document\n","origin_index                                                                                         \n","0             [He, be, suprise, by, the, diversity, of, NLU]  He was suprised by the diversity of NLU"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"IRSEzc-RCceu"},"source":["# 3. Get one row per lemmatized token by setting outputlevel to token.    \n","This lets us compare what the original token was and what it was lemmatized to to. "]},{"cell_type":"code","metadata":{"id":"9bujAZtOCfRW","executionInfo":{"status":"ok","timestamp":1604903315846,"user_tz":-60,"elapsed":14084,"user":{"displayName":"Christian Kasim Loan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqAD-ircKP-s5Eh6JSdkDggDczfqQbJGU_IRb4Hw=s64","userId":"14469489166467359317"}},"outputId":"1507b7ef-2e80-4c62-f8de-6d3eb65cfd21","colab":{"base_uri":"https://localhost:8080/","height":314}},"source":["pipe.predict('He was suprised by the diversity of NLU', output_level='token')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>en_lemma</th>\n","      <th>token</th>\n","    </tr>\n","    <tr>\n","      <th>origin_index</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[He, be, suprise, by, the, diversity, of, NLU]</td>\n","      <td>He</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>[He, be, suprise, by, the, diversity, of, NLU]</td>\n","      <td>was</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>[He, be, suprise, by, the, diversity, of, NLU]</td>\n","      <td>suprised</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>[He, be, suprise, by, the, diversity, of, NLU]</td>\n","      <td>by</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>[He, be, suprise, by, the, diversity, of, NLU]</td>\n","      <td>the</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>[He, be, suprise, by, the, diversity, of, NLU]</td>\n","      <td>diversity</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>[He, be, suprise, by, the, diversity, of, NLU]</td>\n","      <td>of</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>[He, be, suprise, by, the, diversity, of, NLU]</td>\n","      <td>NLU</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                    en_lemma      token\n","origin_index                                                           \n","0             [He, be, suprise, by, the, diversity, of, NLU]         He\n","0             [He, be, suprise, by, the, diversity, of, NLU]        was\n","0             [He, be, suprise, by, the, diversity, of, NLU]   suprised\n","0             [He, be, suprise, by, the, diversity, of, NLU]         by\n","0             [He, be, suprise, by, the, diversity, of, NLU]        the\n","0             [He, be, suprise, by, the, diversity, of, NLU]  diversity\n","0             [He, be, suprise, by, the, diversity, of, NLU]         of\n","0             [He, be, suprise, by, the, diversity, of, NLU]        NLU"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"av7EiK4adb24"},"source":["# 4. Checkout the Lemma models NLU has to offer for other languages than English!"]},{"cell_type":"code","metadata":{"id":"hZ8xLHY7dgJ8","executionInfo":{"status":"ok","timestamp":1604903315851,"user_tz":-60,"elapsed":14081,"user":{"displayName":"Christian Kasim Loan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqAD-ircKP-s5Eh6JSdkDggDczfqQbJGU_IRb4Hw=s64","userId":"14469489166467359317"}},"outputId":"99a45b54-0f2f-4d56-f885-bca9fea457cd","colab":{"base_uri":"https://localhost:8080/"}},"source":["nlu.print_all_model_kinds_for_action('lemma')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["For language <nl> NLU provides the following Models : \n","nlu.load('nl.lemma') returns Spark NLP model lemma\n","For language <en> NLU provides the following Models : \n","nlu.load('en.lemma') returns Spark NLP model lemma_antbnc\n","nlu.load('en.lemma.antbnc') returns Spark NLP model lemma_antbnc\n","For language <fr> NLU provides the following Models : \n","nlu.load('fr.lemma') returns Spark NLP model lemma\n","For language <de> NLU provides the following Models : \n","nlu.load('de.lemma') returns Spark NLP model lemma\n","For language <it> NLU provides the following Models : \n","nlu.load('it.lemma') returns Spark NLP model lemma_dxc\n","nlu.load('it.lemma.dxc') returns Spark NLP model lemma_dxc\n","For language <nb> NLU provides the following Models : \n","nlu.load('nb.lemma') returns Spark NLP model lemma\n","For language <pl> NLU provides the following Models : \n","nlu.load('pl.lemma') returns Spark NLP model lemma\n","For language <pt> NLU provides the following Models : \n","nlu.load('pt.lemma') returns Spark NLP model lemma\n","For language <ru> NLU provides the following Models : \n","nlu.load('ru.lemma') returns Spark NLP model lemma\n","For language <es> NLU provides the following Models : \n","nlu.load('es.lemma') returns Spark NLP model lemma\n","For language <hy> NLU provides the following Models : \n","nlu.load('hy.lemma') returns Spark NLP model lemma\n","For language <eu> NLU provides the following Models : \n","nlu.load('eu.lemma') returns Spark NLP model lemma\n","For language <br> NLU provides the following Models : \n","nlu.load('br.lemma') returns Spark NLP model lemma\n","For language <bg> NLU provides the following Models : \n","nlu.load('bg.lemma') returns Spark NLP model lemma\n","For language <ca> NLU provides the following Models : \n","nlu.load('ca.lemma') returns Spark NLP model lemma\n","For language <cs> NLU provides the following Models : \n","nlu.load('cs.lemma') returns Spark NLP model lemma\n","For language <fi> NLU provides the following Models : \n","nlu.load('fi.lemma') returns Spark NLP model lemma\n","For language <gl> NLU provides the following Models : \n","nlu.load('gl.lemma') returns Spark NLP model lemma\n","For language <el> NLU provides the following Models : \n","nlu.load('el.lemma') returns Spark NLP model lemma\n","For language <hi> NLU provides the following Models : \n","nlu.load('hi.lemma') returns Spark NLP model lemma\n","For language <hu> NLU provides the following Models : \n","nlu.load('hu.lemma') returns Spark NLP model lemma\n","For language <id> NLU provides the following Models : \n","nlu.load('id.lemma') returns Spark NLP model lemma\n","For language <ga> NLU provides the following Models : \n","nlu.load('ga.lemma') returns Spark NLP model lemma\n","For language <da> NLU provides the following Models : \n","nlu.load('da.lemma') returns Spark NLP model lemma\n","For language <la> NLU provides the following Models : \n","nlu.load('la.lemma') returns Spark NLP model lemma\n","For language <lv> NLU provides the following Models : \n","nlu.load('lv.lemma') returns Spark NLP model lemma\n","For language <mr> NLU provides the following Models : \n","nlu.load('mr.lemma') returns Spark NLP model lemma\n","For language <ro> NLU provides the following Models : \n","nlu.load('ro.lemma') returns Spark NLP model lemma\n","For language <sk> NLU provides the following Models : \n","nlu.load('sk.lemma') returns Spark NLP model lemma\n","For language <sl> NLU provides the following Models : \n","nlu.load('sl.lemma') returns Spark NLP model lemma\n","For language <sv> NLU provides the following Models : \n","nlu.load('sv.lemma') returns Spark NLP model lemma\n","For language <tr> NLU provides the following Models : \n","nlu.load('tr.lemma') returns Spark NLP model lemma\n","For language <uk> NLU provides the following Models : \n","nlu.load('uk.lemma') returns Spark NLP model lemma\n","For language <yo> NLU provides the following Models : \n","nlu.load('yo.lemma') returns Spark NLP model lemma\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"TsRxB950elTp"},"source":["## 4.1 Let's try German lematization!"]},{"cell_type":"code","metadata":{"id":"5d_J7-20dvCw","executionInfo":{"status":"ok","timestamp":1604903320153,"user_tz":-60,"elapsed":18377,"user":{"displayName":"Christian Kasim Loan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqAD-ircKP-s5Eh6JSdkDggDczfqQbJGU_IRb4Hw=s64","userId":"14469489166467359317"}},"outputId":"4bc11941-db03-41bc-bf43-dbf0ebe314e2","colab":{"base_uri":"https://localhost:8080/","height":394}},"source":["nlu.load('de.lemma').predict(\"Er war von der Vielfältigkeit des NLU Packets begeistert\",output_level='token')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["lemma download started this may take some time.\n","Approximate size to download 4 MB\n","[OK!]\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>de_lemma</th>\n","      <th>token</th>\n","    </tr>\n","    <tr>\n","      <th>origin_index</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[Er, sein, von, der, Vielfältigkeit, der, NLU,...</td>\n","      <td>Er</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>[Er, sein, von, der, Vielfältigkeit, der, NLU,...</td>\n","      <td>war</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>[Er, sein, von, der, Vielfältigkeit, der, NLU,...</td>\n","      <td>von</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>[Er, sein, von, der, Vielfältigkeit, der, NLU,...</td>\n","      <td>der</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>[Er, sein, von, der, Vielfältigkeit, der, NLU,...</td>\n","      <td>Vielfältigkeit</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>[Er, sein, von, der, Vielfältigkeit, der, NLU,...</td>\n","      <td>des</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>[Er, sein, von, der, Vielfältigkeit, der, NLU,...</td>\n","      <td>NLU</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>[Er, sein, von, der, Vielfältigkeit, der, NLU,...</td>\n","      <td>Packets</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>[Er, sein, von, der, Vielfältigkeit, der, NLU,...</td>\n","      <td>begeistert</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                       de_lemma           token\n","origin_index                                                                   \n","0             [Er, sein, von, der, Vielfältigkeit, der, NLU,...              Er\n","0             [Er, sein, von, der, Vielfältigkeit, der, NLU,...             war\n","0             [Er, sein, von, der, Vielfältigkeit, der, NLU,...             von\n","0             [Er, sein, von, der, Vielfältigkeit, der, NLU,...             der\n","0             [Er, sein, von, der, Vielfältigkeit, der, NLU,...  Vielfältigkeit\n","0             [Er, sein, von, der, Vielfältigkeit, der, NLU,...             des\n","0             [Er, sein, von, der, Vielfältigkeit, der, NLU,...             NLU\n","0             [Er, sein, von, der, Vielfältigkeit, der, NLU,...         Packets\n","0             [Er, sein, von, der, Vielfältigkeit, der, NLU,...      begeistert"]},"metadata":{"tags":[]},"execution_count":10}]}]}