{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5h93jK9WJ6MC"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/enterprise/healthcare/ChunkMergeClinical.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MdE588BiY3z1",
    "outputId": "abb676d5-5868-463a-ed93-7fb2dcfc4de1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['version', 'secret', 'SPARK_NLP_LICENSE', 'JSL_OCR_LICENSE', 'AWS_ACCESS_KEY_ID', 'AWS_SECRET_ACCESS_KEY', 'JSL_OCR_SECRET'])"
      ]
     },
     "execution_count": 1,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('keys.json') as f:\n",
    "    license_keys = json.load(f)\n",
    "\n",
    "license_keys.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "FVFdvGChZDDP",
    "outputId": "9bb5d8f6-29fc-4e6a-f320-72f27e3eadeb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openjdk version \"1.8.0_252\"\n",
      "OpenJDK Runtime Environment (build 1.8.0_252-8u252-b09-1~18.04-b09)\n",
      "OpenJDK 64-Bit Server VM (build 25.252-b09, mixed mode)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.johnsnowlabs.com/8zvTuUjWPt\n",
      "Collecting spark-nlp-jsl==2.5.2\n",
      "Collecting pyspark==2.4.4\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/21/f05c186f4ddb01d15d0ddc36ef4b7e3cedbeb6412274a41f26b55a650ee5/pyspark-2.4.4.tar.gz (215.7MB)\n",
      "\u001b[K     |████████████████████████████████| 215.7MB 62kB/s \n",
      "\u001b[?25hCollecting spark-nlp==2.5.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3e/b0/c272273674b5810c0909b369c57669197907a15d84bbdf058007bb909c99/spark_nlp-2.5.2-py2.py3-none-any.whl (122kB)\n",
      "\u001b[K     |████████████████████████████████| 133kB 42.3MB/s \n",
      "\u001b[?25hCollecting py4j==0.10.7\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
      "\u001b[K     |████████████████████████████████| 204kB 42.9MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyspark: filename=pyspark-2.4.4-py2.py3-none-any.whl size=216130388 sha256=1e8f5143d4c6f668eb8b9c4bb0195775eee9217cf9cc4349d2383fe91eb2dc12\n",
      "  Stored in directory: /root/.cache/pip/wheels/ab/09/4d/0d184230058e654eb1b04467dbc1292f00eaa186544604b471\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark, spark-nlp, spark-nlp-jsl\n",
      "Successfully installed py4j-0.10.7 pyspark-2.4.4 spark-nlp-2.5.2 spark-nlp-jsl-2.5.2\n",
      "2.5.2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Install java\n",
    "! apt-get update -qq\n",
    "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
    "\n",
    "secret = license_keys.get(\"secret\",license_keys.get('SPARK_NLP_SECRET', \"\"))\n",
    "spark_version = os.environ.get(\"SPARK_VERSION\", license_keys.get(\"SPARK_VERSION\",\"2.4\"))\n",
    "version = license_keys.get(\"version\",license_keys.get('SPARK_NLP_PUBLIC_VERSION', \"\"))\n",
    "jsl_version = license_keys.get(\"jsl_version\",license_keys.get('SPARK_NLP_VERSION', \"\"))\n",
    "\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
    "! java -version\n",
    "\n",
    "os.environ['SPARK_NLP_LICENSE'] = license_keys['SPARK_NLP_LICENSE']\n",
    "os.environ['JSL_OCR_LICENSE'] = license_keys['JSL_OCR_LICENSE']\n",
    "os.environ['AWS_ACCESS_KEY_ID']= license_keys['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = license_keys['AWS_SECRET_ACCESS_KEY']\n",
    "\n",
    "print(spark_version, version, jsl_version)\n",
    "\n",
    "! python -m pip install \"pyspark==$spark_version\".*\n",
    "! python -m pip install --upgrade spark-nlp-jsl==$jsl_version  --extra-index-url https://pypi.johnsnowlabs.com/$secret\n",
    "\n",
    "import sparknlp\n",
    "import sparknlp_jsl\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp_jsl.annotator import *\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "print (sparknlp.version())\n",
    "print (sparknlp_jsl.version())\n",
    "\n",
    "spark = sparknlp_jsl.start(secret, gpu=False, spark23=(spark_version[:3]==\"2.3\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O-MbH3GgJ6ML"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import json\n",
    "import os\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp_jsl.annotator import *\n",
    "from sparknlp.base import *\n",
    "import sparknlp_jsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1zgsiTxjaiMd"
   },
   "outputs": [],
   "source": [
    "data_chunk_merge = spark.createDataFrame([\n",
    "  (1,\"\"\"A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to \n",
    "presentation and subsequent type two diabetes mellitus ( T2DM ), one prior episode of HTG-induced pancreatitis \n",
    "three years prior to presentation , associated with an acute hepatitis , and obesity with a body mass index \n",
    "( BMI ) of 33.5 kg/m2 , presented with a one-week history of polyuria , polydipsia , poor appetite , and vomiting.\n",
    "Two weeks prior to presentation , she was treated with a five-day course of amoxicillin for a respiratory tract infection . \n",
    "She was on metformin , glipizide , and dapagliflozin for T2DM and atorvastatin and gemfibrozil for HTG . \n",
    "She had been on dapagliflozin for six months at the time of presentation . Physical examination on presentation was \n",
    "significant for dry oral mucosa ; significantly , her abdominal examination was benign with no tenderness , guarding , \n",
    "or rigidity . Pertinent laboratory findings on admission were : serum glucose 111 mg/dl , bicarbonate 18 mmol/l , \n",
    "anion gap 20 , creatinine 0.4 mg/dL , triglycerides 508 mg/dL , total cholesterol 122 mg/dL , glycated hemoglobin \n",
    "( HbA1c ) 10% , and venous pH 7.27 . Serum lipase was normal at 43 U/L . Serum acetone levels could not be assessed \n",
    "as blood samples kept hemolyzing due to significant lipemia .\n",
    "The patient was initially admitted for starvation ketosis , as she reported poor oral intake for three days prior \n",
    "to admission . However , serum chemistry obtained six hours after presentation revealed her glucose was 186 mg/dL , \n",
    "the anion gap was still elevated at 21 , serum bicarbonate was 16 mmol/L , triglyceride level peaked at 2050 mg/dL , \n",
    "and lipase was 52 U/L .\n",
    " β-hydroxybutyrate level was obtained and found to be elevated at 5.29 mmol/L - the original sample was centrifuged \n",
    " and the chylomicron layer removed prior to analysis due to interference from turbidity caused by lipemia again . \n",
    " The patient was treated with an insulin drip for euDKA and HTG with a reduction in the anion gap to 13 and triglycerides \n",
    " to 1400 mg/dL , within 24 hours .\n",
    " Twenty days ago.\n",
    " Her euDKA was thought to be precipitated by her respiratory tract infection in the setting of SGLT2 inhibitor use . \n",
    " At birth the typical boy is growing slightly faster than the typical girl, but the velocities become equal at about \n",
    " seven months, and then the girl grows faster until four years. \n",
    " From then until adolescence no differences in velocity \n",
    " can be detected. 21-02-2020 \n",
    "21/04/2020\n",
    "\"\"\")]).toDF(\"id\",\"text\")\n",
    "\n",
    "\n",
    "regex = '''(c|p|yc|yp|r|rp|a)?(C[1-5])?M(x|X|0|1[a-d]?),pM\n",
    "(c|p|yc|yp|r|rp|a)?(C[1-5])?N(x|X|0|[1-3][a-d]?),pN\n",
    "(c|p|yc|yp|r|rp|a)?(C[1-5])?T(x|X|is|0|[1-4][a-d]?),pT\n",
    "([0-9]+(\\.[0-9]+)?\\s?x\\s?)*([0-9]+(\\.[0-9]+)?)\\s?(mg|MG|mm|cm|MM|CM|),SIZE\n",
    "at Los Angeles California,LOCATION\n",
    "Zacarias,PERSON\n",
    "better than,BLOCK'''\n",
    "\n",
    "with open('ner_regex.csv', 'w') as f:\n",
    "    f.write(regex)\n",
    "\n",
    "replace_dict = '''pT,TNM\n",
    "pM,TNM'''\n",
    "\n",
    "with open('replace_dict.csv', 'w') as f:\n",
    "    f.write(replace_dict)\n",
    "\n",
    "false_positives = '''beautiful thing,BLOCK'''\n",
    "\n",
    "with open('false_positives.csv', 'w') as f:\n",
    "    f.write(false_positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KfpdGoXGJ6MR"
   },
   "outputs": [],
   "source": [
    "gender = '''male,man,male,boy,gentleman,he,him\n",
    "female,woman,female,girl,lady,old-lady,she,her\n",
    "neutral,neutral'''\n",
    "\n",
    "with open('gender.csv', 'w') as f:\n",
    "    f.write(gender)\n",
    "\n",
    "\n",
    "gender = {\n",
    "  \"entity\": \"Gender\",\n",
    "  \"ruleScope\": \"sentence\", \n",
    "  \"completeMatchRegex\": \"true\"\n",
    "}\n",
    "\n",
    "import json\n",
    "\n",
    "with open('gender.json', 'w') as f:\n",
    "    json.dump(gender, f)\n",
    "\n",
    "\n",
    "date = {\n",
    "  \"entity\": \"Date \",\n",
    "  \"ruleScope\": \"sentence\",\n",
    "  \"regex\": \"\\\\d{1,2}[\\\\/\\\\-\\\\:]{1}(\\\\d{1,2}[\\\\/\\\\-\\\\:]{1}){0,1}\\\\d{2,4}\",\n",
    "  \"valuesDefinition\":[],\n",
    "  \"prefix\": [],\n",
    "  \"suffix\": [],\n",
    "  \"contextLength\": 150,\n",
    "  \"context\": []\n",
    "}\n",
    "\n",
    "with open('date.json', 'w') as f:\n",
    "    json.dump(date, f)\n",
    "\n",
    "\n",
    "age = {\n",
    "  \"entity\": \"Age\",\n",
    "  \"ruleScope\": \"sentence\",\n",
    "   \"matchScope\":\"token\",\n",
    "  \"regex\":\"\\\\s*(0?[1-9]|[1-9][0-9]|[1][1-9][1-9]|200){1,2}[\\\\s-,]+|(?i)\\\\b(?:zero|ten|eleven|twelve|thirteen|fourteen|fifteen|sixteen|seventeen|eighteen|nineteen|twenty)\\\\b(?=\\\\s*year)|\\\\b(?:(?:one|two|three|four|five|six|seven|eight|nine)? hundred(?:\\\\sand)?\\\\s)?(?:(?:twenty|thirty|forty|fifty|sixty|seventy|eighty|ninety)[\\\\s-]?)?\\\\b(?:one|two|three|four|five|six|seven|eight|nine)?(?=\\\\syear)\",\n",
    "  \"prefix\":[\"age of\"],\n",
    "  \"suffix\": [\"-years-old\",\n",
    "             \"years-old\",\n",
    "             \"-year-old\",\n",
    "             \"-months-old\",\n",
    "             \"-month-old\",\n",
    "             \"-months-old\",\n",
    "             \"-day-old\",\n",
    "             \"-days-old\",\n",
    "             \"month old\",\n",
    "             \"days old\",\n",
    "             \"year old\",\n",
    "             \"years old\", \n",
    "             \"years\",\n",
    "             \"year\", \n",
    "             \"months\", \n",
    "             \"old\"\n",
    "              ],\n",
    "  \"contextLength\": 25,\n",
    "  \"context\": [],\n",
    "  \"contextException\": [\"ago\"],\n",
    "  \"exceptionDistance\": 10\n",
    "}\n",
    "\n",
    "with open('age.json', 'w') as f:\n",
    "    json.dump(age, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "weY5V9h7ZDf0"
   },
   "outputs": [],
   "source": [
    "da = DocumentAssembler().setInputCol(\"text\").setOutputCol(\"document\")\n",
    "sd = SentenceDetector().setInputCols(\"document\").setOutputCol(\"sentence\")\n",
    "tk = Tokenizer().setInputCols(\"sentence\").setOutputCol(\"token\")\n",
    "\n",
    "gender_contextual_parser = ContextualParserApproach() \\\n",
    "        .setInputCols([\"sentence\", \"token\"]) \\\n",
    "        .setOutputCol(\"entity_gender\") \\\n",
    "        .setJsonPath(\"gender.json\") \\\n",
    "        .setCaseSensitive(False) \\\n",
    "        .setContextMatch(False)\\\n",
    "        .setDictionary('gender.csv', read_as=ReadAs.TEXT, options={\"delimiter\":\",\"})\n",
    "        \n",
    "age_contextual_parser = ContextualParserApproach() \\\n",
    "        .setInputCols([\"sentence\", \"token\"]) \\\n",
    "        .setOutputCol(\"entity_age\") \\\n",
    "        .setJsonPath(\"age.json\") \\\n",
    "        .setCaseSensitive(False) \\\n",
    "        .setContextMatch(False)\n",
    "        \n",
    "date_contextual_parser = ContextualParserApproach() \\\n",
    "        .setInputCols([\"sentence\", \"token\"]) \\\n",
    "        .setOutputCol(\"entity_date\") \\\n",
    "        .setJsonPath(\"date.json\") \\\n",
    "        .setCaseSensitive(False) \\\n",
    "        .setContextMatch(False)\n",
    "\n",
    "merger1 = ChunkMergeApproach().setInputCols(\"entity_gender\",\"entity_age\").setOutputCol(\"combined\")\n",
    "merger2 = ChunkMergeApproach().setInputCols(\"combined\",\"entity_date\").setOutputCol(\"combined\")\n",
    "\n",
    "pl = Pipeline().setStages([da,sd,tk,gender_contextual_parser,age_contextual_parser,date_contextual_parser,merger1,merger2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2YL6-NtDJ6MX"
   },
   "outputs": [],
   "source": [
    "merged_data = pl.fit(data_chunk_merge).transform(data_chunk_merge).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "ogbBOST6aZTt",
    "outputId": "f2874083-7394-4406-8cb3-c24d737e7732"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---------+------+\n",
      "|id |begin|ner_chunk|entity|\n",
      "+---+-----+---------+------+\n",
      "|1  |14   |female   |Gender|\n",
      "|1  |471  |she      |Gender|\n",
      "|1  |562  |she      |Gender|\n",
      "|1  |668  |she      |Gender|\n",
      "|1  |835  |her      |Gender|\n",
      "|1  |1377 |she      |Gender|\n",
      "|1  |1517 |her      |Gender|\n",
      "|1  |2097 |her      |Gender|\n",
      "|1  |2141 |her      |Gender|\n",
      "|1  |2236 |boy      |Gender|\n",
      "|1  |2284 |girl     |Gender|\n",
      "|1  |2360 |girl     |Gender|\n",
      "+---+-----+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "merged_data.selectExpr(\"id\",\"explode(entity_gender) as a\")\\\n",
    ".selectExpr(\"id\",\"a.begin\",\"a.result as ner_chunk\",\"a.metadata.field as entity\")\\\n",
    ".orderBy(\"id\",\"begin\").show(100, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "8mN01pb9J6Mc",
    "outputId": "6392326c-2ac7-4956-a887-3dc7c774c472"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-----------+------+\n",
      "|id |begin|ner_chunk  |entity|\n",
      "+---+-----+-----------+------+\n",
      "|1  |2    |28-year-old|Age   |\n",
      "+---+-----+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "merged_data.selectExpr(\"id\",\"explode(entity_age) as a\")\\\n",
    ".selectExpr(\"id\",\"a.begin\",\"a.result as ner_chunk\",\"a.metadata.field as entity\")\\\n",
    ".orderBy(\"id\",\"begin\").show(100, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "_bulMjGmJ6Me",
    "outputId": "6c6d52dc-8258-40de-a8f6-b36d2fb2dee8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------+------+\n",
      "|id |begin|ner_chunk |entity|\n",
      "+---+-----+----------+------+\n",
      "|1  |2472 |21-02-2020|Date  |\n",
      "|1  |2484 |21/04/2020|Date  |\n",
      "+---+-----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "merged_data.selectExpr(\"id\",\"explode(entity_date) as a\")\\\n",
    ".selectExpr(\"id\",\"a.begin\",\"a.result as ner_chunk\",\"a.metadata.field as entity\")\\\n",
    ".orderBy(\"id\",\"begin\").show(100, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1NEhjXcfJ6Mh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "dpLba4tAbPiW",
    "outputId": "b49dab7e-b03a-4d2d-8eee-e1bc1c700b01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+------+\n",
      "|id |chunk      |entity|\n",
      "+---+-----------+------+\n",
      "|1  |28-year-old|Age   |\n",
      "|1  |female     |Gender|\n",
      "|1  |she        |Gender|\n",
      "|1  |she        |Gender|\n",
      "|1  |she        |Gender|\n",
      "|1  |her        |Gender|\n",
      "|1  |she        |Gender|\n",
      "|1  |her        |Gender|\n",
      "|1  |her        |Gender|\n",
      "|1  |her        |Gender|\n",
      "|1  |boy        |Gender|\n",
      "|1  |girl       |Gender|\n",
      "|1  |girl       |Gender|\n",
      "|1  |21-02-2020 |Date  |\n",
      "|1  |21/04/2020 |Date  |\n",
      "+---+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "merged_data.selectExpr(\"id\",\"explode(combined) as a\")\\\n",
    ".selectExpr(\"id\",\"a.result as chunk\",\"a.metadata.entity as entity\").show(100, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gdgiRTFGJ6Mn"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ChunkMergeClinical.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "jsl250",
   "language": "python",
   "name": "jsl250"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
