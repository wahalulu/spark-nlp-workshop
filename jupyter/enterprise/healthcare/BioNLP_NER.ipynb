{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5h93jK9WJ6MC"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/enterprise/healthcare/BioNLP_NER.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5HBLgIZnPuze"
   },
   "source": [
    "## BioNLP Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4i7ZpBduPxlg",
    "outputId": "cfe4a323-a748-4f30-f556-54908bebf49a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['SPARK_NLP_PUBLIC_VERSION', 'SPARK_NLP_VERSION', 'SPARK_NLP_SECRET', 'SPARK_NLP_LICENSE', 'AWS_ACCESS_KEY_ID', 'AWS_SECRET_ACCESS_KEY', 'JSL_OCR_LICENSE', 'JSL_OCR_SECRET'])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('keys.json') as f:\n",
    "    license_keys = json.load(f)\n",
    "\n",
    "license_keys.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "id": "OtNEVtvuPxc2",
    "outputId": "af245ff5-873e-41f3-f472-374553942ee0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openjdk version \"1.8.0_252\"\n",
      "OpenJDK Runtime Environment (build 1.8.0_252-8u252-b09-1~18.04-b09)\n",
      "OpenJDK 64-Bit Server VM (build 25.252-b09, mixed mode)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.johnsnowlabs.com/scwgF2mD1U\n",
      "Collecting spark-nlp-jsl==2.5.4rc2\n",
      "Collecting pyspark==2.4.4\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/21/f05c186f4ddb01d15d0ddc36ef4b7e3cedbeb6412274a41f26b55a650ee5/pyspark-2.4.4.tar.gz (215.7MB)\n",
      "\u001b[K     |████████████████████████████████| 215.7MB 52kB/s \n",
      "\u001b[?25hCollecting spark-nlp==2.5.4\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/77/99/7a306dd04623ae25d2bd53a190c0b695fc72043773d5ae0870b7aa53d8e2/spark_nlp-2.5.4-py2.py3-none-any.whl (123kB)\n",
      "\u001b[K     |████████████████████████████████| 133kB 36.9MB/s \n",
      "\u001b[?25hCollecting py4j==0.10.7\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
      "\u001b[K     |████████████████████████████████| 204kB 31.1MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: spark-nlp-jsl, pyspark\n",
      "  Building wheel for spark-nlp-jsl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for spark-nlp-jsl: filename=spark_nlp_jsl-2.5.4rc2-cp36-none-any.whl size=22983 sha256=8d3a831e5323b4c891a6832469c3ced5e3774eecba4fe997fbc1fdaa228c66b0\n",
      "  Stored in directory: /root/.cache/pip/wheels/17/aa/21/fd766748d93cdb7e75f311749ee5e90cc531837704e182302e\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyspark: filename=pyspark-2.4.4-py2.py3-none-any.whl size=216130388 sha256=e8f9ac73a111430b065a343571cf6677c30a73e398a4f03bd84d5ac6d25051ab\n",
      "  Stored in directory: /root/.cache/pip/wheels/ab/09/4d/0d184230058e654eb1b04467dbc1292f00eaa186544604b471\n",
      "Successfully built spark-nlp-jsl pyspark\n",
      "Installing collected packages: py4j, pyspark, spark-nlp, spark-nlp-jsl\n",
      "Successfully installed py4j-0.10.7 pyspark-2.4.4 spark-nlp-2.5.4 spark-nlp-jsl-2.5.4rc2\n",
      "2.5.4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Install java\n",
    "! apt-get update -qq\n",
    "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
    "\n",
    "secret = license_keys.get(\"secret\",license_keys.get('SPARK_NLP_SECRET', \"\"))\n",
    "spark_version = os.environ.get(\"SPARK_VERSION\", license_keys.get(\"SPARK_VERSION\",\"2.4\"))\n",
    "version = license_keys.get(\"version\",license_keys.get('SPARK_NLP_PUBLIC_VERSION', \"\"))\n",
    "jsl_version = license_keys.get(\"jsl_version\",license_keys.get('SPARK_NLP_VERSION', \"\"))\n",
    "\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
    "! java -version\n",
    "\n",
    "os.environ['SPARK_NLP_LICENSE'] = license_keys['SPARK_NLP_LICENSE']\n",
    "os.environ['JSL_OCR_LICENSE'] = license_keys['JSL_OCR_LICENSE']\n",
    "os.environ['AWS_ACCESS_KEY_ID']= license_keys['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = license_keys['AWS_SECRET_ACCESS_KEY']\n",
    "\n",
    "print(spark_version, version, jsl_version)\n",
    "\n",
    "! python -m pip install \"pyspark==$spark_version\".*\n",
    "! python -m pip install --upgrade spark-nlp-jsl==$jsl_version  --extra-index-url https://pypi.johnsnowlabs.com/$secret\n",
    "\n",
    "import sparknlp\n",
    "import sparknlp_jsl\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp_jsl.annotator import *\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "print (sparknlp.version())\n",
    "print (sparknlp_jsl.version())\n",
    "\n",
    "spark = sparknlp_jsl.start(secret, gpu=False, spark23=(spark_version[:3]==\"2.3\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparknlp\n",
    "import sparknlp_jsl\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp_jsl.annotator import *\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "print (sparknlp.version())\n",
    "print (sparknlp_jsl.version())\n",
    "\n",
    "sparknlp_jsl.start(secret, gpu=True, spark23=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "q_acEvbXPuzi",
    "outputId": "64ea9892-e8c7-4874-84ae-9f1a1f865369"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings_clinical download started this may take some time.\n",
      "Approximate size to download 1.6 GB\n",
      "[OK!]\n",
      "pos_clinical download started this may take some time.\n",
      "Approximate size to download 1.7 MB\n",
      "[OK!]\n",
      "dependency_conllu download started this may take some time.\n",
      "Approximate size to download 16.6 MB\n",
      "[OK!]\n",
      "ner_bionlp download started this may take some time.\n",
      "Approximate size to download 13.9 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "document = DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "sentence = SentenceDetector()\\\n",
    "    .setInputCols(['document'])\\\n",
    "    .setOutputCol('sentence')\n",
    "\n",
    "token = Tokenizer()\\\n",
    "    .setInputCols(['sentence'])\\\n",
    "    .setOutputCol('token')\n",
    "\n",
    "embeddings = WordEmbeddingsModel.pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\")\\\n",
    "  .setInputCols([\"sentence\", \"token\"])\\\n",
    "  .setOutputCol(\"embeddings\")\n",
    "\n",
    "clinical_pos = PerceptronModel.pretrained(\"pos_clinical\", \"en\", \"clinical/models\") \\\n",
    "  .setInputCols([\"sentence\", \"token\"]) \\\n",
    "  .setOutputCol(\"pos\")\n",
    "\n",
    "dependency_parser = DependencyParserModel.pretrained(\"dependency_conllu\") \\\n",
    "  .setInputCols([\"sentence\",\"token\", \"pos\"]) \\\n",
    "  .setOutputCol(\"dependency\")\n",
    "\n",
    "bio_ner = NerDLModel.pretrained('ner_bionlp', 'en', 'clinical/models')\n",
    "\n",
    "converter = NerConverter()\\\n",
    "  .setInputCols([\"sentence\", \"token\", \"ner\"])\\\n",
    "  .setOutputCol(\"ner_span\")\n",
    "\n",
    "clinical_ner_pipeline = Pipeline(\n",
    "    stages = [\n",
    "        document,\n",
    "        sentence,\n",
    "        token,\n",
    "        embeddings,\n",
    "        clinical_pos,\n",
    "        dependency_parser,\n",
    "        bio_ner,\n",
    "        converter])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "Apm2EOd3Puzl",
    "outputId": "8017dbf8-cad8-4f00-8525-a95dcdbb56f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|text                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|\n",
      "Stage 4 adenocarcinoma of lung with b/l lung nodules , probable L-2 metastasis and a negative brain MRI . Molecular testing of tumor demonstrates EGFR mutation . On Tarceva . Disease Stable . Plan Chemotherapy toxicity reviewed again . Patient agrees to proceed . Counseling time : 40 mins . 1 ) Continue Tarceva for lung cancer . CT CAP ordered before next visit 2 ) Continue anti-anxiety medication 3 ) Xgeva today 4 ) Return in 1 month with labs , after scan\n",
      "|\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "text=\"\"\"\n",
    "Stage 4 adenocarcinoma of lung with b/l lung nodules , probable L-2 metastasis and a negative brain MRI . Molecular testing of tumor demonstrates EGFR mutation . On Tarceva . Disease Stable . Plan Chemotherapy toxicity reviewed again . Patient agrees to proceed . Counseling time : 40 mins . 1 ) Continue Tarceva for lung cancer . CT CAP ordered before next visit 2 ) Continue anti-anxiety medication 3 ) Xgeva today 4 ) Return in 1 month with labs , after scan\n",
    "\"\"\"\n",
    "\n",
    "prediction_data = spark.createDataFrame([[text]]).toDF(\"text\")\n",
    "\n",
    "prediction_data.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "lGJUJbYgPuzo",
    "outputId": "1293b715-572f-4844-dd25-161a4d617363"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------------+\n",
      "|chunk         |entity                |\n",
      "+--------------+----------------------+\n",
      "|adenocarcinoma|Cancer                |\n",
      "|lung          |Organ                 |\n",
      "|lung nodules  |Pathological_formation|\n",
      "|L-2           |Cell                  |\n",
      "|brain         |Organ                 |\n",
      "|tumor         |Cancer                |\n",
      "|EGFR          |Gene_or_gene_product  |\n",
      "|Tarceva       |Simple_chemical       |\n",
      "|Patient       |Organism              |\n",
      "|lung cancer   |Cancer                |\n",
      "+--------------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prediction_model=clinical_ner_pipeline.fit(prediction_data)\n",
    "\n",
    "preds = prediction_model.transform(prediction_data)\n",
    "\n",
    "preds.select(F.explode(\"ner_span\").alias(\"entities\")) \\\n",
    ".select(F.expr(\"entities.result\").alias(\"chunk\"),\n",
    "        F.expr(\"entities.metadata.entity\").alias(\"entity\"))\\\n",
    "        .show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B6_Lri44Puzr"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "BioNLP-NER.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
