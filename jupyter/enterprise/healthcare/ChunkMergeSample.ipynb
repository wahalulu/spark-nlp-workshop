{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lc_L6EaAWEzo"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/enterprise/healthcare/ChunkMergeSample.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MdE588BiY3z1",
    "outputId": "29dd15c0-3ed4-42a5-d6f6-262ef222dd21"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['version', 'secret', 'SPARK_NLP_LICENSE', 'JSL_OCR_LICENSE', 'AWS_ACCESS_KEY_ID', 'AWS_SECRET_ACCESS_KEY', 'JSL_OCR_SECRET'])"
      ]
     },
     "execution_count": 1,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('keys.json') as f:\n",
    "    license_keys = json.load(f)\n",
    "\n",
    "license_keys.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "FVFdvGChZDDP",
    "outputId": "8c60e6ac-bbc4-4bd2-b2d2-79338959aa82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openjdk version \"1.8.0_252\"\n",
      "OpenJDK Runtime Environment (build 1.8.0_252-8u252-b09-1~18.04-b09)\n",
      "OpenJDK 64-Bit Server VM (build 25.252-b09, mixed mode)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.johnsnowlabs.com/8zvTuUjWPt\n",
      "Collecting spark-nlp-jsl==2.5.2\n",
      "Collecting spark-nlp==2.5.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3e/b0/c272273674b5810c0909b369c57669197907a15d84bbdf058007bb909c99/spark_nlp-2.5.2-py2.py3-none-any.whl (122kB)\n",
      "\u001b[K     |████████████████████████████████| 133kB 2.9MB/s \n",
      "\u001b[?25hCollecting pyspark==2.4.4\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/21/f05c186f4ddb01d15d0ddc36ef4b7e3cedbeb6412274a41f26b55a650ee5/pyspark-2.4.4.tar.gz (215.7MB)\n",
      "\u001b[K     |████████████████████████████████| 215.7MB 58kB/s \n",
      "\u001b[?25hCollecting py4j==0.10.7\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
      "\u001b[K     |████████████████████████████████| 204kB 46.5MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyspark: filename=pyspark-2.4.4-py2.py3-none-any.whl size=216130388 sha256=2082d1f291bf1779d18cdd57753be06fc6e44529f213b5efcdf64925bc64676b\n",
      "  Stored in directory: /root/.cache/pip/wheels/ab/09/4d/0d184230058e654eb1b04467dbc1292f00eaa186544604b471\n",
      "Successfully built pyspark\n",
      "Installing collected packages: spark-nlp, py4j, pyspark, spark-nlp-jsl\n",
      "Successfully installed py4j-0.10.7 pyspark-2.4.4 spark-nlp-2.5.2 spark-nlp-jsl-2.5.2\n",
      "2.5.2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Install java\n",
    "! apt-get update -qq\n",
    "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
    "\n",
    "secret = license_keys.get(\"secret\",license_keys.get('SPARK_NLP_SECRET', \"\"))\n",
    "spark_version = os.environ.get(\"SPARK_VERSION\", license_keys.get(\"SPARK_VERSION\",\"2.4\"))\n",
    "version = license_keys.get(\"version\",license_keys.get('SPARK_NLP_PUBLIC_VERSION', \"\"))\n",
    "jsl_version = license_keys.get(\"jsl_version\",license_keys.get('SPARK_NLP_VERSION', \"\"))\n",
    "\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
    "! java -version\n",
    "\n",
    "os.environ['SPARK_NLP_LICENSE'] = license_keys['SPARK_NLP_LICENSE']\n",
    "os.environ['JSL_OCR_LICENSE'] = license_keys['JSL_OCR_LICENSE']\n",
    "os.environ['AWS_ACCESS_KEY_ID']= license_keys['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = license_keys['AWS_SECRET_ACCESS_KEY']\n",
    "\n",
    "print(spark_version, version, jsl_version)\n",
    "\n",
    "! python -m pip install \"pyspark==$spark_version\".*\n",
    "! python -m pip install --upgrade spark-nlp-jsl==$jsl_version  --extra-index-url https://pypi.johnsnowlabs.com/$secret\n",
    "\n",
    "import sparknlp\n",
    "import sparknlp_jsl\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp_jsl.annotator import *\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "print (sparknlp.version())\n",
    "print (sparknlp_jsl.version())\n",
    "\n",
    "spark = sparknlp_jsl.start(secret, gpu=False, spark23=(spark_version[:3]==\"2.3\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1zgsiTxjaiMd"
   },
   "outputs": [],
   "source": [
    "data_chunk_merge = spark.createDataFrame([\n",
    "  (1,\"Zacarias Woods would not have T2N1 at Los Angeles California where he presented lymphocite leukimia\",),\n",
    "  (2,\"Andre Agassi had 2 x 3 x 1 mm hairwig better than T1N2M1 with adenocarcinoma\",)\n",
    "]).toDF(\"id\",\"text\")\n",
    "\n",
    "regex = '''(c|p|yc|yp|r|rp|a)?(C[1-5])?M(x|X|0|1[a-d]?),pM\n",
    "(c|p|yc|yp|r|rp|a)?(C[1-5])?N(x|X|0|[1-3][a-d]?),pN\n",
    "(c|p|yc|yp|r|rp|a)?(C[1-5])?T(x|X|is|0|[1-4][a-d]?),pT\n",
    "(c|p|yc|yp|r|rp|a)?(C[1-5])?T(x|X|is|0|[1-4][a-d]?),pT\n",
    "([0-9]+(\\.[0-9]+)?\\s?x\\s?)*([0-9]+(\\.[0-9]+)?)\\s?(mg|MG|mm|cm|MM|CM|),SIZE\n",
    "T1N2M1,TNM\n",
    "at Los Angeles California,LOCATION\n",
    "Zacarias,PERSON\n",
    "better than,BLOCK'''\n",
    "\n",
    "with open('ner_regex.csv', 'w') as f:\n",
    "    f.write(regex)\n",
    "\n",
    "replace_dict = '''pT,TNM\n",
    "pM,TNM'''\n",
    "\n",
    "with open('replace_dict.csv', 'w') as f:\n",
    "    f.write(replace_dict)\n",
    "\n",
    "false_positives = '''better than,BLOCK'''\n",
    "\n",
    "with open('false_positives.csv', 'w') as f:\n",
    "    f.write(false_positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "weY5V9h7ZDf0",
    "outputId": "e9c2f9a0-258e-4c19-c34f-a670722fb6c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings_clinical download started this may take some time.\n",
      "Approximate size to download 1.6 GB\n",
      "[OK!]\n",
      "ner_deid_large download started this may take some time.\n",
      "Approximate size to download 14 MB\n",
      "[OK!]\n",
      "ner_bionlp download started this may take some time.\n",
      "Approximate size to download 13.9 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "da = DocumentAssembler().setInputCol(\"text\").setOutputCol(\"document\")\n",
    "sd = SentenceDetector().setInputCols(\"document\").setOutputCol(\"sentence\")\n",
    "tk = Tokenizer().setInputCols(\"sentence\").setOutputCol(\"token\")\n",
    "emb = WordEmbeddingsModel.pretrained(\"embeddings_clinical\",\"en\",\"clinical/models\").setOutputCol(\"embs\")\n",
    "ner = NerDLModel.pretrained(\"ner_deid_large\",\"en\",\"clinical/models\").setInputCols(\"sentence\",\"token\",\"embs\").setOutputCol(\"ner\")\n",
    "canner = NerDLModel.pretrained(\"ner_bionlp\",\"en\",\"clinical/models\").setInputCols(\"sentence\",\"token\",\"embs\").setOutputCol(\"canner\")\n",
    "nc = NerConverter().setInputCols(\"sentence\",\"token\",\"ner\").setOutputCol(\"ner_chunk\")\n",
    "cannc = NerConverter().setInputCols(\"sentence\",\"token\",\"canner\").setOutputCol(\"canner_chunk\")\n",
    "rex = RegexMatcher().setInputCols(\"sentence\").setOutputCol(\"rex\").setExternalRules(\"ner_regex.csv\",\",\",\"TEXT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "45Cr6STSKvZD"
   },
   "outputs": [],
   "source": [
    "#######################################################################################\n",
    "\n",
    "merger_can = ChunkMergeApproach().setInputCols(\"ner_chunk\",\"canner_chunk\").setOutputCol(\"combined\")\\\n",
    "    .setFalsePositivesResource(\"false_positives.csv\",\"TEXT\", {\"delimiter\":\",\"})\\\n",
    "    .setReplaceDictResource(\"replace_dict.csv\",\"TEXT\", {\"delimiter\":\",\"})\n",
    "\n",
    "merger_rex = ChunkMergeApproach().setInputCols(\"combined\",\"rex\").setOutputCol(\"combined\")\\\n",
    "    .setFalsePositivesResource(\"false_positives.csv\",\"TEXT\", {\"delimiter\":\",\"})\\\n",
    "    .setReplaceDictResource(\"replace_dict.csv\",\"TEXT\", {\"delimiter\":\",\"})\\\n",
    "\n",
    "#######################################################################################\n",
    "\n",
    "pl = Pipeline().setStages([da,sd,tk,emb,ner,canner,nc,cannc,rex,merger_can, merger_rex])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8jVGpbBxWEz1"
   },
   "outputs": [],
   "source": [
    "merged_data = pl.fit(data_chunk_merge).transform(data_chunk_merge).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "ogbBOST6aZTt",
    "outputId": "34f9d71a-c029-4803-de40-391ac5720066"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+----------------------+--------+\n",
      "|id |begin|end|ner_chunk             |entity  |\n",
      "+---+-----+---+----------------------+--------+\n",
      "|1  |0    |13 |Zacarias Woods        |NAME    |\n",
      "|1  |38   |59 |Los Angeles California|LOCATION|\n",
      "|1  |80   |98 |lymphocite leukimia   |NAME    |\n",
      "|2  |0    |11 |Andre Agassi          |NAME    |\n",
      "+---+-----+---+----------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "merged_data.selectExpr(\"id\",\"explode(ner_chunk) as a\")\\\n",
    ".selectExpr(\"id\",\"a.begin\",\"a.end\",\"a.result as ner_chunk\",\"a.metadata.entity\")\\\n",
    ".orderBy(\"id\",\"begin\").show(100, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "bYlwmyDhfwNa",
    "outputId": "2dba5268-483f-4a1f-ad09-21c982c5c536"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+--------------+--------------------+\n",
      "|id |begin|end|ner_chunk     |entity              |\n",
      "+---+-----+---+--------------+--------------------+\n",
      "|1  |0    |7  |Zacarias      |Gene_or_gene_product|\n",
      "|2  |6    |11 |Agassi        |Gene_or_gene_product|\n",
      "|2  |50   |55 |T1N2M1        |Gene_or_gene_product|\n",
      "|2  |62   |75 |adenocarcinoma|Cancer              |\n",
      "+---+-----+---+--------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "merged_data.selectExpr(\"id\",\"explode(canner_chunk) as a\")\\\n",
    ".selectExpr(\"id\",\"a.begin\",\"a.end\",\"a.result as ner_chunk\",\"a.metadata.entity\")\\\n",
    ".orderBy(\"id\",\"begin\").show(100, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "-1RFnel-WEz7",
    "outputId": "befcbb84-fd3e-45b5-8733-182935ac349a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+-------------------------+--------+\n",
      "|id |begin|end|ner_chunk                |entity  |\n",
      "+---+-----+---+-------------------------+--------+\n",
      "|1  |0    |7  |Zacarias                 |PERSON  |\n",
      "|1  |30   |31 |T2                       |pT      |\n",
      "|1  |30   |31 |T2                       |pT      |\n",
      "|1  |31   |31 |2                        |SIZE    |\n",
      "|1  |32   |33 |N1                       |pN      |\n",
      "|1  |33   |34 |1                        |SIZE    |\n",
      "|1  |35   |59 |at Los Angeles California|LOCATION|\n",
      "|2  |17   |28 |2 x 3 x 1 mm             |SIZE    |\n",
      "|2  |38   |48 |better than              |BLOCK   |\n",
      "|2  |50   |51 |T1                       |pT      |\n",
      "|2  |50   |51 |T1                       |pT      |\n",
      "|2  |50   |55 |T1N2M1                   |TNM     |\n",
      "|2  |51   |51 |1                        |SIZE    |\n",
      "|2  |52   |53 |N2                       |pN      |\n",
      "|2  |53   |53 |2                        |SIZE    |\n",
      "|2  |54   |55 |M1                       |pM      |\n",
      "|2  |55   |56 |1                        |SIZE    |\n",
      "+---+-----+---+-------------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "merged_data.selectExpr(\"id\",\"explode(rex) as a\")\\\n",
    ".selectExpr(\"id\",\"a.begin\",\"a.end\",\"a.result as ner_chunk\",\"a.metadata.identifier as entity\")\\\n",
    ".orderBy(\"id\",\"begin\").show(100, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "dpLba4tAbPiW",
    "outputId": "11291ecd-8002-4a9d-954d-19445251a160"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------------+--------------------+\n",
      "|id |chunk                    |entity              |\n",
      "+---+-------------------------+--------------------+\n",
      "|1  |Zacarias Woods           |NAME                |\n",
      "|1  |T2                       |TNM                 |\n",
      "|1  |N1                       |pN                  |\n",
      "|1  |at Los Angeles California|LOCATION            |\n",
      "|1  |lymphocite leukimia      |NAME                |\n",
      "|2  |Andre Agassi             |NAME                |\n",
      "|2  |2 x 3 x 1 mm             |SIZE                |\n",
      "|2  |T1N2M1                   |Gene_or_gene_product|\n",
      "|2  |adenocarcinoma           |Cancer              |\n",
      "+---+-------------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "merged_data.selectExpr(\"id\",\"explode(combined) as a\")\\\n",
    ".selectExpr(\"id\",\"a.result as chunk\",\"a.metadata.entity as entity\").show(100, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KtaZ8EBBWE0B"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ChunkMergeSample.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "jsl250",
   "language": "python",
   "name": "jsl250"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
